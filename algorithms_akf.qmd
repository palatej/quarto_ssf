# Augmented filter

The augmented filter is based on papers of De Jong et al. See more especially De Jong and Chu-Chun-Lin \[2003\]. So, when we talk about the augmented Kalman filter (AKF), we talk about the solution proposed by De Jong, Its implementation in JD+ contains a few modifications in comparison with the reference paper.

A first approach consists in transforming the state space form into a regression model. We build recursively the regression variables $X$ generated by the diffuse constraints and we apply the Kalman filter on $y, X$ to get $y_L, X_L$. The least squares problem obtained that way is then solved by a robust algorithm like the QR decomposition. See the chapter on the computation of the likelihood for more details. The solution is computed with all the data (no "collapsing out" of the diffuse effects). Even if this solution is not the most parsimonious one, it is usually the most robust one.

A second approach consists in using the first data to get a rapid estimate of the diffuse effects, in "re-injecting" that estimate in the model and in finishing the processing with the ordinary Kalman filter (the so-called augmented Kalman filter with a collapsing out of the diffuse initialization). Usually, that collapsing is processed as quickly as possible, though it is not mandatory. A better strategy would consist in waiting till we have a robust enough estimate of the diffuse effects (using for instance a condition number; not implemented yet).

So, in the first case, we consider

$$
\begin{align*}
B_t &= \prod{T_0...T_{t-1}}B \\
B_t &= T_{t-1}B_{t-1} \quad, \text{with } B_0=B \\
X_t &= Z_t B_T
\end{align*}
$$ 

Applying the filter on $y$ and on $X$ gives

$$
\begin{align*}
e_t &= y_t-Z_t a_t \\
{y_L}_t &= e_t / \sqrt f_t \\
a_{t+1} &= T_t a_t + \tilde{K_t} {y_L}_t \\
E_t &= X_t - Z_t A_t = Z_t (B_t - A_t) \\ 
{X_L}_t &= (Z_t B_t - Z_t A_t) / \sqrt f_t \\
A_{t+1} &= T_t A_t + \tilde{K_t} {X_L}_t \quad \text{, with }A_0 = 0 
\end{align*}
$$ 

Considering the following recursions

$$
\begin{align*}
\tilde{A_o} &= B_0 \\
\tilde{E_t} &= 0 -  Z_t \tilde A_t \\
\tilde {X_L}_t &= ( - Z_t \tilde A_t) / \sqrt f_t \\
\tilde A_{t+1} &= T_t \tilde A_t + \tilde{K_t} \tilde{X_L}_t
\end{align*}
$$ 

We can easily check by induction that:

$$
\begin{align*}
\tilde{A_t} &= B_t - A_t \\
\tilde E_t &= - E_t \\
\tilde {X_L}_t &= - {X_L}_t
\end{align*}
$$ 

De Jong used in his paper the second form, which is slightly faster. The first form should be used if the marginal likelihood is needed (explicit computation of $X$)

## Q Matrix

In the original paper, the so-called $Q$ matrix "accumulates" the filtered quantities and their interactions. It is defined recursively by

$$
Q_t = Q_{t-1} + (E_t, e_t)' {f_t}^{-1} (E_t, e_t) \quad , Q_{-1} = 0
$$ 

or

$$
Q_t = Q_{t-1} + (-\tilde{E_t}, e_t)' {f_t}^{-1} (-\tilde{E_t}, e_t) \quad , Q_{-1} = 0
$$ 


In a more compact form, it gives

$$
Q_t = Q_{t-1} + ( {X_L}_t, {y_l}_t)'( {X_L}_t, {y_l}_t)
$$ 

or

$$
Q_t = Q_{t-1} + (-\tilde {X_L}_t, {y_l}_t)'(-\tilde {X_L}_t, {y_l}_t)
$$ 

If we write

$$
Q_m = 
\begin{pmatrix}
S & s \\
s' & q
\end{pmatrix}
$$ we have that the ml estimator of $\delta$ after $m$ observations is $-S^{-1}s$ and that the ml estimator of $\sigma^2$ is $q/m$ We re-inject the effect of the diffuse initialization by adding to $a_m, P_m, q_m$ respectively \$-A_m S\^{-1}s, A_m S\^{-1} A_m', -s' S\^{-1} s \$

To find the "collapsing point" $m$, $S$ must be invertible. Several approaches can be considered to achieve that goal.

-   Use directly the $Q$ matrix and check the invertibility of $S$ by Cholesky
-   Triangularize $Q$ either completely or triangularize only $S$ by means of (fast) Givens transformations, so that S in never explicitly computed
-   Accumulate $(\tilde {X_L}_t, {y_l}_t)$ in a matrix and use QR (recursively or not) to find the corresponding least squares problem
-   ...

A more stable version will use the Cholesky factor of the matrix Q (t omitted)

$$
Q=\begin{pmatrix}
A & 0 \\
b & c
\end{pmatrix}
$$

So, we have that:

$$
\begin{align*}
S = AA' \\
s = A b' \\
q=b b' + c^2 \\
s' S^{-1} s = b A' (AA')^{-1} A b' = b b' \\
q - s' S^{-1} s = c^2 \\
S^{-1} s = (AA')^{-1} A b' = A'^{-1}b'
\end{align*}
$$

The ml estimator of $\delta$ is then $bA^{-1}$ and the ml estimator of $\sigma^2$ is $c^2$

The augmented filter is identical to the ordinary filter augmented by the effects due to the diffuse initialization. The new equations are:

### Univariate model

#### Update step t

$$
\begin{align*}
E_t &= - Z_t A_t \\
A_{t|t} &= A_t + M_t f_t^{-1}E_t 
\end{align*}
$$

#### Forecast step t

$$
\begin{align*}
A_{t+1} &= T_t A_{t|t} \\
\end{align*}
$$

#### Q update

We consider the matrix $\tilde Q \sim (d+1) \times (d+2)$

$$
Q_t=\begin{pmatrix}
S_t & s_t \\
{s_t}' & q_t
\end{pmatrix}
$$

A more stable version will use the Cholesky factor of the matrix Q (t omitted)

$$
\tilde Q_t=
\begin{pmatrix}
A_t & 0 & 0\\
b_t & c_t & 0
\end{pmatrix}
$$ We have that

$$
\tilde Q_t \tilde {Q_t}'=
\begin{pmatrix}
S_t & s'_t\\
s_t & q_t
\end{pmatrix}
$$ We update $\tilde Q_t$ as follows: $$ 
\tilde Q_t=
\begin{pmatrix}
A_t & 0 & E_t f_t^{-1}\\
b_t & c_t &  e  f_t^{-1}
\end{pmatrix}
$$ We then triangularize Q by means of (fast) Givens rotations (Householder reflections could also be used but, as the matrix contains many $0$, they are slower) and we get

$$
\tilde Q_{t+1}=
\begin{pmatrix}
A_{t+1} & 0 & 0\\
b_{t+1} & c_{t+1} & 0
\end{pmatrix}
$$

When $A_t$ is non singular, the model can be "collapsed" (see below) and the the filtering will switch to the ordinary filter. That is the default option. Otherwise, the QR filter should be preferred. See ...

#### Collapsing

$$ 
\begin{align*}
B &= A^{-1}B \\
a &= a - \delta B \\
P &= P + BB'
\end{align*}
$$
