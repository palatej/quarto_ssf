# Augmented filters

The augmented filters are based on papers of De Jong et al. See more especially De Jong and Chu-Chun-Lin \[2003\]. So, when we talk about the augmented Kalman filters (AKF), we talk about the solution proposed by De Jong, Its implementation in JD+ contains a few modifications in comparison with the reference paper.

## Filtering

A first approach consists in transforming the state space form into a regression model. We build recursively the regression variables $X$ generated by the diffuse constraints and we apply the Kalman filter on $y, X$ to get $y_L, X_L$. The least squares problem obtained that way is then solved by a robust algorithm like the QR decomposition. See the chapter on the computation of the likelihood for more details. The solution is computed with all the data (no "collapsing out" of the diffuse effects). Even if this solution is not the most parsimonious one, it is usually quite robust.

A second approach consists in using the first data to get a rapid estimate of the diffuse effects, in "re-injecting" that estimate in the model and in finishing the processing with the ordinary Kalman filter (the so-called augmented Kalman filter with a collapsing out of the diffuse initialization). Usually, that collapsing is processed as quickly as possible, though it is not mandatory. A better strategy would consist in waiting till we have a robust enough estimate of the diffuse effects (using for instance some condition number; see below for the solution used in JD+).

So, in the first case, we consider

$$
\begin{align*}
B_t &= \prod{T_0...T_{t-1}}B \\
\text{or } B_t &= T_{t-1}B_{t-1} \quad, \text{with } B_0=B \\
X_t &= Z_t B_T
\end{align*}
$$

Applying the filter on $y$ and on $X$ gives

$$
\begin{align*}
e_t &= y_t-Z_t a_t \\
{y_L}_t &= e_t / \sqrt f_t \\
a_{t+1} &= T_t a_t + \tilde{K_t} {y_L}_t \\
E_t &= X_t - Z_t A_t = Z_t (B_t - A_t) \\ 
{X_L}_t &= (Z_t B_t - Z_t A_t) / \sqrt f_t \\
A_{t+1} &= T_t A_t + \tilde{K_t} {X_L}_t \quad \text{, with }A_0 = 0 
\end{align*}
$$ Equivalently, we can use the following recursions

$$
\begin{align*}
\tilde{A_o} &= B_0 \\
\tilde{E_t} &= 0 -  Z_t \tilde A_t \\
\tilde {X_L}_t &= ( - Z_t \tilde A_t) / \sqrt f_t \\
\tilde A_{t+1} &= T_t \tilde A_t + \tilde{K_t} \tilde{X_L}_t
\end{align*}
$$

We can easily check by induction that:

$$
\begin{align*}
\tilde{A_t} &= B_t - A_t \\
\tilde E_t &= - E_t \\
\tilde {X_L}_t &= - {X_L}_t
\end{align*}
$$

De Jong used in his paper the second form, which is slightly faster. The first form should be used if the marginal likelihood is needed (explicit computation of $X$)

The augmented filter is identical to the ordinary filter augmented by the effects due to the diffuse initialization. Using the notations of the ordinary filter, the new equations are:

### Update step t

In the univariate case, we add:

$$
\begin{align*}
E_t &= - Z_t A_t \\
A_{t|t} &= A_t + M_t f_t^{-1}E_t 
\end{align*}
$$ In the multivariate case, we use:

$$
\begin{align*}
E_t &= - Z_t A_t \\
Ut &= R_t^{-1}E_t \\
A_{t|t} &= A_t + \tilde {M_t} U_t 
\end{align*}
$$

### Forecast step t

$$
\begin{align*}
A_{t+1} &= T_t A_{t|t} \\
\end{align*}
$$

### Q Matrix

The results of the previous iterations must be stored to compute the usual statistics or additional results (likelihood, smoothing...) In the original paper, the so-called $Q$ matrix "accumulates" the filtered quantities and their interactions. It is defined recursively by

$$
Q_t = Q_{t-1} + (E_t, e_t)' {f_t}^{-1} (E_t, e_t) \quad , Q_{-1} = 0
$$

or

$$
Q_t = Q_{t-1} + (-\tilde{E_t}, e_t)' {f_t}^{-1} (-\tilde{E_t}, e_t) \quad , Q_{-1} = 0
$$

In a more compact form, it gives

$$
Q_t = Q_{t-1} + ( {X_L}_t, {y_l}_t)'( {X_L}_t, {y_l}_t)
$$

or

$$
Q_t = Q_{t-1} + (-\tilde {X_L}_t, {y_l}_t)'(-\tilde {X_L}_t, {y_l}_t)
$$

If we write

$$
Q_m = 
\begin{pmatrix}
S & s \\
s' & q
\end{pmatrix}
$$

we have that the ml estimator of $\delta$ after $m$ observations is $S^{-1}s$ and that the ml estimator of $\sigma^2$ is $q/m$ We re-inject the effect of the diffuse initialization by adding to $a_m, P_m, q_m$ respectively $-A_m S^{-1}s, A_m S^{-1} A_m', s' S^{-1} s$

To find the "collapsing point" $m$, $S$ must be invertible. Several approaches can be considered to achieve that goal.

-   Use directly the $Q$ matrix and check the invertibility of $S$ by Cholesky
-   Triangularize $Q$ either completely or triangularize only $S$ by means of (fast) Givens transformations, so that S in never explicitly computed
-   Accumulate $(\tilde {X_L}_t, {y_l}_t)$ in a matrix and use QR (recursively or not) to find the corresponding least squares problem
-   ...

See below some explanations on the triangularization of Q (t omitted).

We suppose that the triangular form of $Q$ is $Q_T$ so that $Q = Q_T Q_T'$

$$
Q_T=\begin{pmatrix}
A & 0 \\
b & c
\end{pmatrix}
$$

We have that:

$$
\begin{align*}
S = AA' \\
s = A b' \\
q=b b' + c^2 \\
s' S^{-1} s = b A' (AA')^{-1} A b' = b b' \\
q - s' S^{-1} s = c^2 \\
S^{-1} s = (AA')^{-1} A b' = A'^{-1}b'
\end{align*}
$$

The ml estimator of $\delta$ is then $bA^{-1}$, its variance $\Psi= S^{-1}$ s  and the ml estimator of $\sigma^2$ is $c^2/n$

### Collapsing

As mentioned above, the collapsing is performed as follow:

$$ 
\begin{align*}
a_{m_c} &= a_m - A_m \hat{\delta} \\
P_{m_c} &= P_m + A_m \Psi A_m'
\end{align*}
$$

## Smoothing

### Computation of the smoothations

$$ 
\begin{align*}
K_t &= T_t P_t Z_t' {f_t}^{-1} \\
\tilde e_t &=  f_t^{-1}e_t - K_t'r_t \\
\tilde E_t &=  f_t^{-1}E_t - K_t'R_t \\
var(\tilde e_t) &= f_t^{-1} + K_t' N_t K_t \\
var(\tilde E_t) &= f_t^{-1} + K_t' N_t K_t \\
\end{align*}
$$

### Main recursions

$$ 
\begin{align*}
r_{t-1}' &= \tilde e_t Z_t + r_t' T_t \\
R_{t-1}' &= \tilde E_t Z_t + R_t' T_t \\
L_t &= T_t - K_t Z_t \\
N_{t-1} &= Z_t' f_t^{-1} Z_t + L_t' N_t L_t 
\end{align*}
$$

### Update of the state

$$ 
\begin{align*}
&\text{using } B_t = A_t + P_t R_{t-1} \\
\hat \delta &= E(\delta \vert y) = S^{-1}s\\
\Psi &= var(\delta \vert y) = S^{-1} \\
\tilde a_t &= a_t + P_t r_{t-1} + B_t \hat \delta \\
\tilde P_t &= P_t - P_t N_{t-1} P_t +B_t \Psi B_t'
\end{align*}
$$

### Update of the state in the case of collapsing in $m$

$$ 
\begin{align*}
\hat \delta = E(\delta \vert y) &= S^{-1}(s + A'_m r_{m-1}) \\
\Psi = var(\delta \vert y) & = S^{-1} - S^{-1}(A_m' N_{m-1} A_m)S^{-1} \\
\end{align*}
$$ $$ 
\begin{align*}
C_t &= P_t(R_{t-1} + N_{t-1} A_t) \\
\tilde a_t &= a_t + P_t r_{t-1} + B_t \hat \delta \\
\tilde P_t &= P_t - P_t N_{t-1} P_t + B_t \Psi B_t'- B_t S^{-1} C'_t - C_t S^{-1} B'_t
\end{align*}
$$
